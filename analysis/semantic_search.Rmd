```{r setup, include=FALSE}
# Required R package installation:
# These will install packages if they are not already installed
# Set the correct default repository
r = getOption("repos")
r["CRAN"] = "http://cran.rstudio.com"
options(repos = r)


if (!require("knitr")) {
  install.packages("knitr")
  library(knitr)
}

if (!require("elastic")) {
  install.packages("elastic")
  library(elastic)
}

if (!require("lubridate")) {
  install.packages("lubridate")
  library(lubridate)
}

if (!require("httr")) {
  install.packages("httr")
  library(httr)
}

if (!require("jsonlite")) {
  install.packages("jsonlite")
  library(jsonlite)
}

if (!require("kableExtra")) {
  install.packages("kableExtra")
  library(kableExtra)
}

knitr::opts_chunk$set(echo = TRUE)
```

## Demo for semantic similarity search using Universal Sentence Encoder embeddings and Elasticsearch.

### Configure the search parameters here - set date range and semantic phrase:

Note: large date ranges can take some time to process on initial search due to the sheer volume of data we have collected. Subsequent searches using the same date range should run quickly due to Elasticsearch caching.

```{r}
# query start date/time (inclusive)
rangestart <- ymd_hms("2020-03-30 00:00:00")

# query end date/time (exclusive)
rangeend <- ymd_hms("2020-04-04 00:00:00")

# query semantic similarity phrase (choose one of these examples or enter your own)
semantic_phrase <- "Elementary school students are not coping well with distance learning."
#semantic_phrase <- "How do you stay at home when you are homeless?"
#semantic_phrase <- "My wedding has been postponed due to the coronavirus."
#semantic_phrase <- "I lost my job because of COVID-19. How am I going to be able to make rent?"
#semantic_phrase <- "I am diabetic and out of work because of coronavirus. I am worried I won't be able to get insulin without insurance."
#semantic_phrase <- "There is going to be a COVID-19 baby boom..."

# number of results to return (max 10,000)
resultsize <- 50
```

### Results:

```{r, echo=FALSE}
########################################################################################
# Embedding server info
embed_use_large_url <- "http://localhost:8080/embed/use_large/"

# Elasticsearch instance info
elasticsearch_host <- ""
elasticsearch_path <- "elasticsearch"
elasticsearch_port <- 443
elasticsearch_schema <- "https"

# Elasticsearch index name
indexname <- "coronavirus-data-all"

# Fields to include in results
resultfields <- '"id_str", "created_at", "user.screen_name", "text", "extended_tweet.full_text"'
########################################################################################

embed_use_large <- function(text) {
  req <- paste(embed_use_large_url, URLencode(text, reserved=TRUE), sep="")
  res <- GET(req)
  res.text <- content(res, "text", encoding="UTF-8")
  res.json <- fromJSON(res.text)
  text_embedding <- res.json$use_large
}

conn <- connect(host = elasticsearch_host,
                path = elasticsearch_path, 
                port = elasticsearch_port, 
                transport_schema = elasticsearch_schema,
                errors="complete")

gte_str = format(rangestart, "%Y-%m-%dT%H:%M:%S")
lt_str = format(rangeend, "%Y-%m-%dT%H:%M:%S")

if (semantic_phrase == "") {
  query <- sprintf('{
    "sort" : [
      { "created_at" : "asc" }
    ],
    "_source": [%s],
    "query": {
      "bool": {
        "filter": [
          {
            "range" : {
              "created_at" : {
                "gte": "%s",
                "lt": "%s",
                "format": "strict_date_hour_minute_second",
                "time_zone": "+00:00"
              }
            }
          },
          {
            "bool": {
              "must_not": {
                "exists": {
                  "field": "retweeted_status.id"
                }
              }
            }
          }
        ]
      }
    }
  }', resultfields, gte_str, lt_str)
} else {
  text_embedding <- embed_use_large(semantic_phrase)
  query <- sprintf('{
    "_source": [%s],
    "query": {
      "script_score": {
        "query": {
          "bool": {
            "filter": [
              {
                "range" : {
                  "created_at" : {
                    "gte": "%s",
                    "lt": "%s",
                    "format": "strict_date_hour_minute_second",
                    "time_zone": "+00:00"
                  }
                }
              },
              {
                "exists": { "field": "embedding.use_large.primary" }
              }
            ]
          }
        },
        "script": {
          "source": "cosineSimilarity(params.query_vector, \'embedding.use_large.primary\') + 1.0",
          "params": {"query_vector": %s}
        }
      }
    }
  }', resultfields, gte_str, lt_str, toJSON(text_embedding))
}

results <- Search(conn, index=indexname, body=query, size=resultsize, asdf=TRUE)
results.total <- results$hits$total$value
results.df <- results$hits$hits[,c(4, 6:ncol(results$hits$hits))]

#fix score for semantic search
if (semantic_phrase != "") {
  results.df$`_score` <- results.df$`_score` - 1.0
  colnames(results.df)[1] <- "cosine_similarity"
}

#fix column names
colnames(results.df) <- sub("_source.", "", colnames(results.df))
colnames(results.df) <- sub("extended_tweet.entities.", "extended_tweet.entities.full_", colnames(results.df))
colnames(results.df) <- sub("extended_tweet.", "", colnames(results.df))
colnames(results.df) <- sub("entities.", "", colnames(results.df))
colnames(results.df) <- sub("user.", "user_", colnames(results.df))
#merge 'text' and 'full_text'
if ("full_text" %in% colnames(results.df)) {
  results.df$full_text <- ifelse(is.na(results.df$full_text), results.df$text, results.df$full_text)
} else {
  results.df$full_text <- results.df$text
}

#print results
params.df <- data.frame(from=rangestart, to=rangeend, phrase=semantic_phrase)
kable(params.df) %>% kable_styling()

display.df <- results.df[, c("cosine_similarity", "full_text", "created_at", "user_screen_name")]
kable(display.df) %>% kable_styling()
```